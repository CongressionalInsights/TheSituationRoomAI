{
  "id": "arxiv-ai",
  "fetchedAt": 1771776526988,
  "contentType": "application/atom+xml; charset=utf-8",
  "body": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/vLCmJh+cSjpRTe+CD7vJBA8w+qc</id>\n  <title>arXiv Query: search_query=cat:cs.AI&amp;id_list=&amp;start=0&amp;max_results=20</title>\n  <updated>2026-02-22T16:08:46Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=cat:cs.AI&amp;start=0&amp;max_results=20&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>20</opensearch:itemsPerPage>\n  <opensearch:totalResults>163755</opensearch:totalResults>\n  <opensearch:startIndex>0</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2602.17664v1</id>\n    <title>Sink-Aware Pruning for Diffusion Language Models</title>\n    <updated>2026-02-19T18:59:50Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.17664v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.17664v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Diffusion Language Models (DLMs) incur high inference cost due to iterative denoising, motivating efficient pruning. Existing pruning heuristics largely inherited from autoregressive (AR) LLMs, typically preserve attention sink tokens because AR sinks serve as stable global anchors. We show that this assumption does not hold for DLMs: the attention-sink position exhibits substantially higher variance over the full generation trajectory (measured by how the dominant sink locations shift across timesteps), indicating that sinks are often transient and less structurally essential than in AR models. Based on this observation, we propose ${\\bf \\texttt{Sink-Aware Pruning}}$, which automatically identifies and prunes unstable sinks in DLMs (prior studies usually keep sinks for AR LLMs). Without retraining, our method achieves a better quality-efficiency trade-off and outperforms strong prior pruning baselines under matched compute. Our code is available at https://github.com/VILA-Lab/Sink-Aware-Pruning.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-19T18:59:50Z</published>\n    <arxiv:comment>Code at: https://github.com/VILA-Lab/Sink-Aware-Pruning</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Aidar Myrzakhan</name>\n    </author>\n    <author>\n      <name>Tianyi Li</name>\n    </author>\n    <author>\n      <name>Bowei Guo</name>\n    </author>\n    <author>\n      <name>Shengkun Tang</name>\n    </author>\n    <author>\n      <name>Zhiqiang Shen</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2602.17663v1</id>\n    <title>CLEF HIPE-2026: Evaluating Accurate and Efficient Person-Place Relation Extraction from Multilingual Historical Texts</title>\n    <updated>2026-02-19T18:59:44Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.17663v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.17663v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>HIPE-2026 is a CLEF evaluation lab dedicated to person-place relation extraction from noisy, multilingual historical texts. Building on the HIPE-2020 and HIPE-2022 campaigns, it extends the series toward semantic relation extraction by targeting the task of identifying person--place associations in multiple languages and time periods. Systems are asked to classify relations of two types - $at$ (\"Has the person ever been at this place?\") and $isAt$ (\"Is the person located at this place around publication time?\") - requiring reasoning over temporal and geographical cues. The lab introduces a three-fold evaluation profile that jointly assesses accuracy, computational efficiency, and domain generalization. By linking relation extraction to large-scale historical data processing, HIPE-2026 aims to support downstream applications in knowledge-graph construction, historical biography reconstruction, and spatial analysis in digital humanities.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-19T18:59:44Z</published>\n    <arxiv:comment>ECIR 2026. CLEF Evaluation Lab. Registration DL: 2026/04/23. Task Homepage at https://hipe-eval.github.io/HIPE-2026/</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Juri Opitz</name>\n    </author>\n    <author>\n      <name>Corina Raclé</name>\n    </author>\n    <author>\n      <name>Emanuela Boros</name>\n    </author>\n    <author>\n      <name>Andrianos Michail</name>\n    </author>\n    <author>\n      <name>Matteo Romanello</name>\n    </author>\n    <author>\n      <name>Maud Ehrmann</name>\n    </author>\n    <author>\n      <name>Simon Clematide</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2602.17658v1</id>\n    <title>MARS: Margin-Aware Reward-Modeling with Self-Refinement</title>\n    <updated>2026-02-19T18:59:03Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.17658v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.17658v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Reward modeling is a core component of modern alignment pipelines including RLHF and RLAIF, underpinning policy optimization methods including PPO and TRPO. However, training reliable reward models relies heavily on human-labeled preference data, which is costly and limited, motivating the use of data augmentation. Existing augmentation approaches typically operate at the representation or semantic level and remain agnostic to the reward model's estimation difficulty. In this paper, we propose MARS, an adaptive, margin-aware augmentation and sampling strategy that explicitly targets ambiguous and failure modes of the reward model. Our proposed framework, MARS, concentrates augmentation on low-margin (ambiguous) preference pairs where the reward model is most uncertain, and iteratively refines the training distribution via hard-sample augmentation. We provide theoretical guarantees showing that this strategy increases the average curvature of the loss function hence enhance information and improves conditioning, along with empirical results demonstrating consistent gains over uniform augmentation for robust reward modeling.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.IT\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-19T18:59:03Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Payel Bhattacharjee</name>\n    </author>\n    <author>\n      <name>Osvaldo Simeone</name>\n    </author>\n    <author>\n      <name>Ravi Tandon</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2602.17645v1</id>\n    <title>Pushing the Frontier of Black-Box LVLM Attacks via Fine-Grained Detail Targeting</title>\n    <updated>2026-02-19T18:54:32Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.17645v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.17645v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Black-box adversarial attacks on Large Vision-Language Models (LVLMs) are challenging due to missing gradients and complex multimodal boundaries. While prior state-of-the-art transfer-based approaches like M-Attack perform well using local crop-level matching between source and target images, we find this induces high-variance, nearly orthogonal gradients across iterations, violating coherent local alignment and destabilizing optimization. We attribute this to (i) ViT translation sensitivity that yields spike-like gradients and (ii) structural asymmetry between source and target crops. We reformulate local matching as an asymmetric expectation over source transformations and target semantics, and build a gradient-denoising upgrade to M-Attack. On the source side, Multi-Crop Alignment (MCA) averages gradients from multiple independently sampled local views per iteration to reduce variance. On the target side, Auxiliary Target Alignment (ATA) replaces aggressive target augmentation with a small auxiliary set from a semantically correlated distribution, producing a smoother, lower-variance target manifold. We further reinterpret momentum as Patch Momentum, replaying historical crop gradients; combined with a refined patch-size ensemble (PE+), this strengthens transferable directions. Together these modules form M-Attack-V2, a simple, modular enhancement over M-Attack that substantially improves transfer-based black-box attacks on frontier LVLMs: boosting success rates on Claude-4.0 from 8% to 30%, Gemini-2.5-Pro from 83% to 97%, and GPT-5 from 98% to 100%, outperforming prior black-box LVLM attacks. Code and data are publicly available at: https://github.com/vila-lab/M-Attack-V2.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-19T18:54:32Z</published>\n    <arxiv:comment>Code at: https://github.com/vila-lab/M-Attack-V2</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Xiaohan Zhao</name>\n    </author>\n    <author>\n      <name>Zhaoyi Li</name>\n    </author>\n    <author>\n      <name>Yaxin Luo</name>\n    </author>\n    <author>\n      <name>Jiacheng Cui</name>\n    </author>\n    <author>\n      <name>Zhiqiang Shen</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2602.17641v1</id>\n    <title>FAMOSE: A ReAct Approach to Automated Feature Discovery</title>\n    <updated>2026-02-19T18:53:15Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.17641v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.17641v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Feature engineering remains a critical yet challenging bottleneck in machine learning, particularly for tabular data, as identifying optimal features from an exponentially large feature space traditionally demands substantial domain expertise. To address this challenge, we introduce FAMOSE (Feature AugMentation and Optimal Selection agEnt), a novel framework that leverages the ReAct paradigm to autonomously explore, generate, and refine features while integrating feature selection and evaluation tools within an agent architecture. To our knowledge, FAMOSE represents the first application of an agentic ReAct framework to automated feature engineering, especially for both regression and classification tasks. Extensive experiments demonstrate that FAMOSE is at or near the state-of-the-art on classification tasks (especially tasks with more than 10K instances, where ROC-AUC increases 0.23% on average), and achieves the state-of-the-art for regression tasks by reducing RMSE by 2.0% on average, while remaining more robust to errors than other algorithms. We hypothesize that FAMOSE's strong performance is because ReAct allows the LLM context window to record (via iterative feature discovery and evaluation steps) what features did or did not work. This is similar to a few-shot prompt and guides the LLM to invent better, more innovative features. Our work offers evidence that AI agents are remarkably effective in solving problems that require highly inventive solutions, such as feature engineering.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-19T18:53:15Z</published>\n    <arxiv:comment>23 pages, 6 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Keith Burghardt</name>\n    </author>\n    <author>\n      <name>Jienan Liu</name>\n    </author>\n    <author>\n      <name>Sadman Sakib</name>\n    </author>\n    <author>\n      <name>Yuning Hao</name>\n    </author>\n    <author>\n      <name>Bo Li</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2602.17634v1</id>\n    <title>Reverso: Efficient Time Series Foundation Models for Zero-shot Forecasting</title>\n    <updated>2026-02-19T18:48:08Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.17634v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.17634v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Learning time series foundation models has been shown to be a promising approach for zero-shot time series forecasting across diverse time series domains. Insofar as scaling has been a critical driver of performance of foundation models in other modalities such as language and vision, much recent work on time series foundation modeling has focused on scaling. This has resulted in time series foundation models with hundreds of millions of parameters that are, while performant, inefficient and expensive to use in practice. This paper describes a simple recipe for learning efficient foundation models for zero-shot time series forecasting that are orders of magnitude smaller. We show that large-scale transformers are not necessary: small hybrid models that interleave long convolution and linear RNN layers (in particular DeltaNet layers) can match the performance of larger transformer-based models while being more than a hundred times smaller. We also describe several data augmentation and inference strategies that further improve performance. This recipe results in Reverso, a family of efficient time series foundation models for zero-shot forecasting that significantly push the performance-efficiency Pareto frontier.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-19T18:48:08Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Xinghong Fu</name>\n    </author>\n    <author>\n      <name>Yanhong Li</name>\n    </author>\n    <author>\n      <name>Georgios Papaioannou</name>\n    </author>\n    <author>\n      <name>Yoon Kim</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2602.17633v1</id>\n    <title>When to Trust the Cheap Check: Weak and Strong Verification for Reasoning</title>\n    <updated>2026-02-19T18:47:38Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.17633v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.17633v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Reasoning with LLMs increasingly unfolds inside a broader verification loop. Internally, systems use cheap checks, such as self-consistency or proxy rewards, which we call weak verification. Externally, users inspect outputs and steer the model through feedback until results are trustworthy, which we call strong verification. These signals differ sharply in cost and reliability: strong verification can establish trust but is resource-intensive, while weak verification is fast and scalable but noisy and imperfect. We formalize this tension through weak--strong verification policies, which decide when to accept or reject based on weak verification and when to defer to strong verification. We introduce metrics capturing incorrect acceptance, incorrect rejection, and strong-verification frequency. Over population, we show that optimal policies admit a two-threshold structure and that calibration and sharpness govern the value of weak verifiers. Building on this, we develop an online algorithm that provably controls acceptance and rejection errors without assumptions on the query stream, the language model, or the weak verifier.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-19T18:47:38Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Shayan Kiyani</name>\n    </author>\n    <author>\n      <name>Sima Noorani</name>\n    </author>\n    <author>\n      <name>George Pappas</name>\n    </author>\n    <author>\n      <name>Hamed Hassani</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2602.17632v1</id>\n    <title>SMAC: Score-Matched Actor-Critics for Robust Offline-to-Online Transfer</title>\n    <updated>2026-02-19T18:47:31Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.17632v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.17632v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Modern offline Reinforcement Learning (RL) methods find performant actor-critics, however, fine-tuning these actor-critics online with value-based RL algorithms typically causes immediate drops in performance. We provide evidence consistent with the hypothesis that, in the loss landscape, offline maxima for prior algorithms and online maxima are separated by low-performance valleys that gradient-based fine-tuning traverses. Following this, we present Score Matched Actor-Critic (SMAC), an offline RL method designed to learn actor-critics that transition to online value-based RL algorithms with no drop in performance. SMAC avoids valleys between offline and online maxima by regularizing the Q-function during the offline phase to respect a first-order derivative equality between the score of the policy and action-gradient of the Q-function. We experimentally demonstrate that SMAC converges to offline maxima that are connected to better online maxima via paths with monotonically increasing reward found by first-order optimization. SMAC achieves smooth transfer to Soft Actor-Critic and TD3 in 6/6 D4RL tasks. In 4/6 environments, it reduces regret by 34-58% over the best baseline.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-19T18:47:31Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Nathan S. de Lara</name>\n    </author>\n    <author>\n      <name>Florian Shkurti</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2602.17616v1</id>\n    <title>Stable Asynchrony: Variance-Controlled Off-Policy RL for LLMs</title>\n    <updated>2026-02-19T18:40:51Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.17616v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.17616v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Reinforcement learning (RL) is widely used to improve large language models on reasoning tasks, and asynchronous RL training is attractive because it increases end-to-end throughput. However, for widely adopted critic-free policy-gradient methods such as REINFORCE and GRPO, high asynchrony makes the policy-gradient estimator markedly $\\textbf{higher variance}$: training on stale rollouts creates heavy-tailed importance ratios, causing a small fraction of samples to dominate updates. This amplification makes gradients noisy and learning unstable relative to matched on-policy training. Across math and general reasoning benchmarks, we find collapse is reliably predicted by effective sample size (ESS) and unstable gradient norms. Motivated by this diagnosis, we propose $\\textbf{V}$ariance $\\textbf{C}$ontrolled $\\textbf{P}$olicy $\\textbf{O}$ptimization ($\\textbf{VCPO}$), a general stabilization method for REINFORCE/GRPO-style algorithms that (i) scales learning rate based on effective sample size to dampen unreliable updates, and (ii) applies a closed-form minimum-variance baseline for the off-policy setting, avoiding an auxiliary value model and adding minimal overhead. Empirically, VCPO substantially improves robustness for asynchronous training across math, general reasoning, and tool-use tasks, outperforming a broad suite of baselines spanning masking/clipping stabilizers and algorithmic variants. This reduces long-context, multi-turn training time by 2.5$\\times$ while matching synchronous performance, demonstrating that explicit control of policy-gradient variance is key for reliable asynchronous RL at scale.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-19T18:40:51Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Luke Huang</name>\n    </author>\n    <author>\n      <name>Zhuoyang Zhang</name>\n    </author>\n    <author>\n      <name>Qinghao Hu</name>\n    </author>\n    <author>\n      <name>Shang Yang</name>\n    </author>\n    <author>\n      <name>Song Han</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2505.02819v4</id>\n    <title>ReplaceMe: Network Simplification via Depth Pruning and Transformer Block Linearization</title>\n    <updated>2026-02-19T18:32:53Z</updated>\n    <link href=\"https://arxiv.org/abs/2505.02819v4\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2505.02819v4\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>We introduce ReplaceMe, a generalized training-free depth pruning method that effectively replaces transformer blocks with a linear operation, while maintaining high performance for low compression ratios. In contrast to conventional pruning approaches that require additional training or fine-tuning, our approach requires only a small calibration dataset that is used to estimate a linear transformation, which approximates the pruned blocks. The estimated linear mapping can be seamlessly merged with the remaining transformer blocks, eliminating the need for any additional network parameters. Our experiments show that ReplaceMe consistently outperforms other training-free approaches and remains highly competitive with state-of-the-art pruning methods that involve extensive retraining/fine-tuning and architectural modifications. Applied to several large language models (LLMs), ReplaceMe achieves up to 25\\% pruning while retaining approximately 90\\% of the original model's performance on open benchmarks - without any training or healing steps, resulting in minimal computational overhead. We provide an open-source library implementing ReplaceMe alongside several state-of-the-art depth pruning techniques, available at https://github.com/mts-ai/ReplaceMe</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-05-05T17:47:42Z</published>\n    <arxiv:comment>This work was accepted and presented at NeurIPS 2025. Code is available at https://github.com/mts-ai/replaceme Reviews at OpenReview: https://openreview.net/forum?id=zEj1FSYCRn NeurIPS 2025 Proceedings: https://openreview.net/pdf?id=zEj1FSYCRn</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Dmitriy Shopkhoev</name>\n    </author>\n    <author>\n      <name>Ammar Ali</name>\n    </author>\n    <author>\n      <name>Magauiya Zhussip</name>\n    </author>\n    <author>\n      <name>Valentin Malykh</name>\n    </author>\n    <author>\n      <name>Stamatios Lefkimmiatis</name>\n    </author>\n    <author>\n      <name>Nikos Komodakis</name>\n    </author>\n    <author>\n      <name>Sergey Zagoruyko</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2602.17608v1</id>\n    <title>Towards Anytime-Valid Statistical Watermarking</title>\n    <updated>2026-02-19T18:32:26Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.17608v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.17608v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The proliferation of Large Language Models (LLMs) necessitates efficient mechanisms to distinguish machine-generated content from human text. While statistical watermarking has emerged as a promising solution, existing methods suffer from two critical limitations: the lack of a principled approach for selecting sampling distributions and the reliance on fixed-horizon hypothesis testing, which precludes valid early stopping. In this paper, we bridge this gap by developing the first e-value-based watermarking framework, Anchored E-Watermarking, that unifies optimal sampling with anytime-valid inference. Unlike traditional approaches where optional stopping invalidates Type-I error guarantees, our framework enables valid, anytime-inference by constructing a test supermartingale for the detection process. By leveraging an anchor distribution to approximate the target model, we characterize the optimal e-value with respect to the worst-case log-growth rate and derive the optimal expected stopping time. Our theoretical claims are substantiated by simulations and evaluations on established benchmarks, showing that our framework can significantly enhance sample efficiency, reducing the average token budget required for detection by 13-15% relative to state-of-the-art baselines.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-19T18:32:26Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Baihe Huang</name>\n    </author>\n    <author>\n      <name>Eric Xu</name>\n    </author>\n    <author>\n      <name>Kannan Ramchandran</name>\n    </author>\n    <author>\n      <name>Jiantao Jiao</name>\n    </author>\n    <author>\n      <name>Michael I. Jordan</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2602.17607v1</id>\n    <title>AutoNumerics: An Autonomous, PDE-Agnostic Multi-Agent Pipeline for Scientific Computing</title>\n    <updated>2026-02-19T18:31:52Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.17607v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.17607v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>PDEs are central to scientific and engineering modeling, yet designing accurate numerical solvers typically requires substantial mathematical expertise and manual tuning. Recent neural network-based approaches improve flexibility but often demand high computational cost and suffer from limited interpretability. We introduce \\texttt{AutoNumerics}, a multi-agent framework that autonomously designs, implements, debugs, and verifies numerical solvers for general PDEs directly from natural language descriptions. Unlike black-box neural solvers, our framework generates transparent solvers grounded in classical numerical analysis. We introduce a coarse-to-fine execution strategy and a residual-based self-verification mechanism. Experiments on 24 canonical and real-world PDE problems demonstrate that \\texttt{AutoNumerics} achieves competitive or superior accuracy compared to existing neural and LLM-based baselines, and correctly selects numerical schemes based on PDE structural properties, suggesting its viability as an accessible paradigm for automated PDE solving.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.NA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-19T18:31:52Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Jianda Du</name>\n    </author>\n    <author>\n      <name>Youran Sun</name>\n    </author>\n    <author>\n      <name>Haizhao Yang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2602.17605v1</id>\n    <title>Adapting Actively on the Fly: Relevance-Guided Online Meta-Learning with Latent Concepts for Geospatial Discovery</title>\n    <updated>2026-02-19T18:30:18Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.17605v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.17605v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>In many real-world settings, such as environmental monitoring, disaster response, or public health, with costly and difficult data collection and dynamic environments, strategically sampling from unobserved regions is essential for efficiently uncovering hidden targets under tight resource constraints. Yet, sparse and biased geospatial ground truth limits the applicability of existing learning-based methods, such as reinforcement learning. To address this, we propose a unified geospatial discovery framework that integrates active learning, online meta-learning, and concept-guided reasoning. Our approach introduces two key innovations built on a shared notion of *concept relevance*, which captures how domain-specific factors influence target presence: a *concept-weighted uncertainty sampling strategy*, where uncertainty is modulated by learned relevance based on readily-available domain-specific concepts (e.g., land cover, source proximity); and a *relevance-aware meta-batch formation strategy* that promotes semantic diversity during online-meta updates, improving generalization in dynamic environments. Our experiments include testing on a real-world dataset of cancer-causing PFAS (Per- and polyfluoroalkyl substances) contamination, showcasing our method's reliability at uncovering targets with limited data and a varying environment.</summary>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-19T18:30:18Z</published>\n    <arxiv:primary_category term=\"cs.CV\"/>\n    <author>\n      <name>Jowaria Khan</name>\n    </author>\n    <author>\n      <name>Anindya Sarkar</name>\n    </author>\n    <author>\n      <name>Yevgeniy Vorobeychik</name>\n    </author>\n    <author>\n      <name>Elizabeth Bondi-Kelly</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.14974v3</id>\n    <title>pi-Flow: Policy-Based Few-Step Generation via Imitation Distillation</title>\n    <updated>2026-02-19T18:30:05Z</updated>\n    <link href=\"https://arxiv.org/abs/2510.14974v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2510.14974v3\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Few-step diffusion or flow-based generative models typically distill a velocity-predicting teacher into a student that predicts a shortcut towards denoised data. This format mismatch has led to complex distillation procedures that often suffer from a quality-diversity trade-off. To address this, we propose policy-based flow models ($π$-Flow). $π$-Flow modifies the output layer of a student flow model to predict a network-free policy at one timestep. The policy then produces dynamic flow velocities at future substeps with negligible overhead, enabling fast and accurate ODE integration on these substeps without extra network evaluations. To match the policy's ODE trajectory to the teacher's, we introduce a novel imitation distillation approach, which matches the policy's velocity to the teacher's along the policy's trajectory using a standard $\\ell_2$ flow matching loss. By simply mimicking the teacher's behavior, $π$-Flow enables stable and scalable training and avoids the quality-diversity trade-off. On ImageNet 256$^2$, it attains a 1-NFE FID of 2.85, outperforming previous 1-NFE models of the same DiT architecture. On FLUX.1-12B and Qwen-Image-20B at 4 NFEs, $π$-Flow achieves substantially better diversity than state-of-the-art DMD models, while maintaining teacher-level quality.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-10-16T17:59:51Z</published>\n    <arxiv:comment>ICLR 2026. Code: https://github.com/Lakonik/piFlow Demos: https://huggingface.co/spaces/Lakonik/pi-Qwen | https://huggingface.co/spaces/Lakonik/pi-FLUX.1 | https://huggingface.co/spaces/Lakonik/pi-FLUX.2</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Hansheng Chen</name>\n    </author>\n    <author>\n      <name>Kai Zhang</name>\n    </author>\n    <author>\n      <name>Hao Tan</name>\n    </author>\n    <author>\n      <name>Leonidas Guibas</name>\n    </author>\n    <author>\n      <name>Gordon Wetzstein</name>\n    </author>\n    <author>\n      <name>Sai Bi</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2602.17602v1</id>\n    <title>MolHIT: Advancing Molecular-Graph Generation with Hierarchical Discrete Diffusion Models</title>\n    <updated>2026-02-19T18:27:11Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.17602v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.17602v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Molecular generation with diffusion models has emerged as a promising direction for AI-driven drug discovery and materials science. While graph diffusion models have been widely adopted due to the discrete nature of 2D molecular graphs, existing models suffer from low chemical validity and struggle to meet the desired properties compared to 1D modeling. In this work, we introduce MolHIT, a powerful molecular graph generation framework that overcomes long-standing performance limitations in existing methods. MolHIT is based on the Hierarchical Discrete Diffusion Model, which generalizes discrete diffusion to additional categories that encode chemical priors, and decoupled atom encoding that splits the atom types according to their chemical roles. Overall, MolHIT achieves new state-of-the-art performance on the MOSES dataset with near-perfect validity for the first time in graph diffusion, surpassing strong 1D baselines across multiple metrics. We further demonstrate strong performance in downstream tasks, including multi-property guided generation and scaffold extension.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-19T18:27:11Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Hojung Jung</name>\n    </author>\n    <author>\n      <name>Rodrigo Hormazabal</name>\n    </author>\n    <author>\n      <name>Jaehyeong Jo</name>\n    </author>\n    <author>\n      <name>Youngrok Park</name>\n    </author>\n    <author>\n      <name>Kyunggeun Roh</name>\n    </author>\n    <author>\n      <name>Se-Young Yun</name>\n    </author>\n    <author>\n      <name>Sehui Han</name>\n    </author>\n    <author>\n      <name>Dae-Woong Jeong</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2602.17598v1</id>\n    <title>The Cascade Equivalence Hypothesis: When Do Speech LLMs Behave Like ASR$\\rightarrow$LLM Pipelines?</title>\n    <updated>2026-02-19T18:22:39Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.17598v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.17598v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Current speech LLMs largely perform implicit ASR: on tasks solvable from a transcript, they are behaviorally and mechanistically equivalent to simple Whisper$\\to$LLM cascades. We show this through matched-backbone testing across four speech LLMs and six tasks, controlling for the LLM backbone for the first time. Ultravox is statistically indistinguishable from its matched cascade ($κ{=}0.93$); logit lens reveals literal text emerging in hidden states; LEACE concept erasure confirms text representations are causally necessary in both architectures tested, collapsing accuracy to near-zero. Qwen2-Audio genuinely diverges, revealing cascade equivalence is architecture-dependent, not universal. For most deployed use cases, current speech LLMs are expensive cascades, and under noise, they are worse ones, with clean-condition advantages reversing by up to 7.6% at 0 dB.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"eess.AS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-19T18:22:39Z</published>\n    <arxiv:comment>10 pages, 6 figures, 7 tables</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Jayadev Billa</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2602.14879v2</id>\n    <title>CT-Bench: A Benchmark for Multimodal Lesion Understanding in Computed Tomography</title>\n    <updated>2026-02-19T18:19:25Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.14879v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.14879v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Artificial intelligence (AI) can automatically delineate lesions on computed tomography (CT) and generate radiology report content, yet progress is limited by the scarcity of publicly available CT datasets with lesion-level annotations. To bridge this gap, we introduce CT-Bench, a first-of-its-kind benchmark dataset comprising two components: a Lesion Image and Metadata Set containing 20,335 lesions from 7,795 CT studies with bounding boxes, descriptions, and size information, and a multitask visual question answering benchmark with 2,850 QA pairs covering lesion localization, description, size estimation, and attribute categorization. Hard negative examples are included to reflect real-world diagnostic challenges. We evaluate multiple state-of-the-art multimodal models, including vision-language and medical CLIP variants, by comparing their performance to radiologist assessments, demonstrating the value of CT-Bench as a comprehensive benchmark for lesion analysis. Moreover, fine-tuning models on the Lesion Image and Metadata Set yields significant performance gains across both components, underscoring the clinical utility of CT-Bench.</summary>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-16T16:10:19Z</published>\n    <arxiv:primary_category term=\"cs.CV\"/>\n    <author>\n      <name>Qingqing Zhu</name>\n    </author>\n    <author>\n      <name>Qiao Jin</name>\n    </author>\n    <author>\n      <name>Tejas S. Mathai</name>\n    </author>\n    <author>\n      <name>Yin Fang</name>\n    </author>\n    <author>\n      <name>Zhizheng Wang</name>\n    </author>\n    <author>\n      <name>Yifan Yang</name>\n    </author>\n    <author>\n      <name>Maame Sarfo-Gyamfi</name>\n    </author>\n    <author>\n      <name>Benjamin Hou</name>\n    </author>\n    <author>\n      <name>Ran Gu</name>\n    </author>\n    <author>\n      <name>Praveen T. S. Balamuralikrishna</name>\n    </author>\n    <author>\n      <name>Kenneth C. Wang</name>\n    </author>\n    <author>\n      <name>Ronald M. Summers</name>\n    </author>\n    <author>\n      <name>Zhiyong Lu</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2602.17594v1</id>\n    <title>AI Gamestore: Scalable, Open-Ended Evaluation of Machine General Intelligence with Human Games</title>\n    <updated>2026-02-19T18:17:25Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.17594v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.17594v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Rigorously evaluating machine intelligence against the broad spectrum of human general intelligence has become increasingly important and challenging in this era of rapid technological advance. Conventional AI benchmarks typically assess only narrow capabilities in a limited range of human activity. Most are also static, quickly saturating as developers explicitly or implicitly optimize for them. We propose that a more promising way to evaluate human-like general intelligence in AI systems is through a particularly strong form of general game playing: studying how and how well they play and learn to play \\textbf{all conceivable human games}, in comparison to human players with the same level of experience, time, or other resources. We define a \"human game\" to be a game designed by humans for humans, and argue for the evaluative suitability of this space of all such games people can imagine and enjoy -- the \"Multiverse of Human Games\". Taking a first step towards this vision, we introduce the AI GameStore, a scalable and open-ended platform that uses LLMs with humans-in-the-loop to synthesize new representative human games, by automatically sourcing and adapting standardized and containerized variants of game environments from popular human digital gaming platforms. As a proof of concept, we generated 100 such games based on the top charts of Apple App Store and Steam, and evaluated seven frontier vision-language models (VLMs) on short episodes of play. The best models achieved less than 10\\% of the human average score on the majority of the games, and especially struggled with games that challenge world-model learning, memory and planning. We conclude with a set of next steps for building out the AI GameStore as a practical way to measure and drive progress toward human-like general intelligence in machines.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-19T18:17:25Z</published>\n    <arxiv:comment>29 pages, 14 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Lance Ying</name>\n    </author>\n    <author>\n      <name>Ryan Truong</name>\n    </author>\n    <author>\n      <name>Prafull Sharma</name>\n    </author>\n    <author>\n      <name>Kaiya Ivy Zhao</name>\n    </author>\n    <author>\n      <name>Nathan Cloos</name>\n    </author>\n    <author>\n      <name>Kelsey R. Allen</name>\n    </author>\n    <author>\n      <name>Thomas L. Griffiths</name>\n    </author>\n    <author>\n      <name>Katherine M. Collins</name>\n    </author>\n    <author>\n      <name>José Hernández-Orallo</name>\n    </author>\n    <author>\n      <name>Phillip Isola</name>\n    </author>\n    <author>\n      <name>Samuel J. Gershman</name>\n    </author>\n    <author>\n      <name>Joshua B. Tenenbaum</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2602.15277v2</id>\n    <title>Accelerating Large-Scale Dataset Distillation via Exploration-Exploitation Optimization</title>\n    <updated>2026-02-19T18:14:28Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.15277v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.15277v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Dataset distillation compresses the original data into compact synthetic datasets, reducing training time and storage while retaining model performance, enabling deployment under limited resources. Although recent decoupling-based distillation methods enable dataset distillation at large scale, they continue to face an efficiency gap: optimization-based decoupling methods achieve higher accuracy but demand intensive computation, whereas optimization-free decoupling methods are efficient but sacrifice accuracy. To overcome this trade-off, we propose Exploration--Exploitation Distillation (E$^2$D), a simple, practical method that minimizes redundant computation through an efficient pipeline that begins with full-image initialization to preserve semantic integrity and feature diversity. It then uses a two-phase optimization strategy: an exploration phase that performs uniform updates and identifies high-loss regions, and an exploitation phase that focuses updates on these regions to accelerate convergence. We evaluate E$^2$D on large-scale benchmarks, surpassing the state-of-the-art on ImageNet-1K while being $18\\times$ faster, and on ImageNet-21K, our method substantially improves accuracy while remaining $4.3\\times$ faster. These results demonstrate that targeted, redundancy-reducing updates, rather than brute-force optimization, bridge the gap between accuracy and efficiency in large-scale dataset distillation. Code is available at https://github.com/ncsu-dk-lab/E2D.</summary>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-17T00:27:58Z</published>\n    <arxiv:primary_category term=\"cs.CV\"/>\n    <author>\n      <name>Muhammad J. Alahmadi</name>\n    </author>\n    <author>\n      <name>Peng Gao</name>\n    </author>\n    <author>\n      <name>Feiyi Wang</name>\n    </author>\n    <author>\n      <name>Dongkuan Xu</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2602.17586v1</id>\n    <title>Conditional Flow Matching for Continuous Anomaly Detection in Autonomous Driving on a Manifold-Aware Spectral Space</title>\n    <updated>2026-02-19T18:10:16Z</updated>\n    <link href=\"https://arxiv.org/abs/2602.17586v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2602.17586v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Safety validation for Level 4 autonomous vehicles (AVs) is currently bottlenecked by the inability to scale the detection of rare, high-risk long-tail scenarios using traditional rule-based heuristics. We present Deep-Flow, an unsupervised framework for safety-critical anomaly detection that utilizes Optimal Transport Conditional Flow Matching (OT-CFM) to characterize the continuous probability density of expert human driving behavior. Unlike standard generative approaches that operate in unstable, high-dimensional coordinate spaces, Deep-Flow constrains the generative process to a low-rank spectral manifold via a Principal Component Analysis (PCA) bottleneck. This ensures kinematic smoothness by design and enables the computation of the exact Jacobian trace for numerically stable, deterministic log-likelihood estimation. To resolve multi-modal ambiguity at complex junctions, we utilize an Early Fusion Transformer encoder with lane-aware goal conditioning, featuring a direct skip-connection to the flow head to maintain intent-integrity throughout the network. We introduce a kinematic complexity weighting scheme that prioritizes high-energy maneuvers (quantified via path tortuosity and jerk) during the simulation-free training process. Evaluated on the Waymo Open Motion Dataset (WOMD), our framework achieves an AUC-ROC of 0.766 against a heuristic golden set of safety-critical events. More significantly, our analysis reveals a fundamental distinction between kinematic danger and semantic non-compliance. Deep-Flow identifies a critical predictability gap by surfacing out-of-distribution behaviors, such as lane-boundary violations and non-normative junction maneuvers, that traditional safety filters overlook. This work provides a mathematically rigorous foundation for defining statistical safety gates, enabling objective, data-driven validation for the safe deployment of autonomous fleets.</summary>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-02-19T18:10:16Z</published>\n    <arxiv:primary_category term=\"cs.RO\"/>\n    <author>\n      <name>Antonio Guillen-Perez</name>\n    </author>\n  </entry>\n</feed>\n",
  "httpStatus": 200
}