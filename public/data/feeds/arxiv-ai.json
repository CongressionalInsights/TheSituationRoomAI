{
  "id": "arxiv-ai",
  "fetchedAt": 1768507942891,
  "contentType": "application/atom+xml; charset=utf-8",
  "body": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/vLCmJh+cSjpRTe+CD7vJBA8w+qc</id>\n  <title>arXiv Query: search_query=cat:cs.AI&amp;id_list=&amp;start=0&amp;max_results=20</title>\n  <updated>2026-01-15T19:08:24Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=cat:cs.AI&amp;start=0&amp;max_results=20&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>20</opensearch:itemsPerPage>\n  <opensearch:totalResults>158190</opensearch:totalResults>\n  <opensearch:startIndex>0</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2601.09708v1</id>\n    <title>Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning</title>\n    <updated>2026-01-14T18:59:59Z</updated>\n    <link href=\"https://arxiv.org/abs/2601.09708v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2601.09708v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Vision-Language-Action (VLA) tasks require reasoning over complex visual scenes and executing adaptive actions in dynamic environments. While recent studies on reasoning VLAs show that explicit chain-of-thought (CoT) can improve generalization, they suffer from high inference latency due to lengthy reasoning traces. We propose Fast-ThinkAct, an efficient reasoning framework that achieves compact yet performant planning through verbalizable latent reasoning. Fast-ThinkAct learns to reason efficiently with latent CoTs by distilling from a teacher, driven by a preference-guided objective to align manipulation trajectories that transfers both linguistic and visual planning capabilities for embodied control. This enables reasoning-enhanced policy learning that effectively connects compact reasoning to action execution. Extensive experiments across diverse embodied manipulation and reasoning benchmarks demonstrate that Fast-ThinkAct achieves strong performance with up to 89.3\\% reduced inference latency over state-of-the-art reasoning VLAs, while maintaining effective long-horizon planning, few-shot adaptation, and failure recovery.</summary>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-01-14T18:59:59Z</published>\n    <arxiv:comment>Project page: https://jasper0314-huang.github.io/fast-thinkact/</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CV\"/>\n    <author>\n      <name>Chi-Pin Huang</name>\n    </author>\n    <author>\n      <name>Yunze Man</name>\n    </author>\n    <author>\n      <name>Zhiding Yu</name>\n    </author>\n    <author>\n      <name>Min-Hung Chen</name>\n    </author>\n    <author>\n      <name>Jan Kautz</name>\n    </author>\n    <author>\n      <name>Yu-Chiang Frank Wang</name>\n    </author>\n    <author>\n      <name>Fu-En Yang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2601.09706v1</id>\n    <title>Value-Aware Numerical Representations for Transformer Language Models</title>\n    <updated>2026-01-14T18:59:14Z</updated>\n    <link href=\"https://arxiv.org/abs/2601.09706v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2601.09706v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Transformer-based language models often achieve strong results on mathematical reasoning benchmarks while remaining fragile on basic numerical understanding and arithmetic operations. A central limitation is that numbers are processed as symbolic tokens whose embeddings do not explicitly encode numerical value, leading to systematic errors. We introduce a value-aware numerical representation that augments standard tokenized inputs with a dedicated prefix token whose embedding is explicitly conditioned on the underlying numerical value. This mechanism injects magnitude information directly into the model's input space while remaining compatible with existing tokenizers and decoder-only Transformer architectures. Evaluation on arithmetic tasks shows that the proposed approach outperforms baselines across numerical formats, tasks, and operand lengths. These results indicate that explicitly encoding numerical value is an effective and efficient way to improve fundamental numerical robustness in language models.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-01-14T18:59:14Z</published>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Andreea Dutulescu</name>\n    </author>\n    <author>\n      <name>Stefan Ruseti</name>\n    </author>\n    <author>\n      <name>Mihai Dascalu</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2601.09703v1</id>\n    <title>ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation</title>\n    <updated>2026-01-14T18:57:31Z</updated>\n    <link href=\"https://arxiv.org/abs/2601.09703v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2601.09703v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Code generation tasks aim to automate the conversion of user requirements into executable code, significantly reducing manual development efforts and enhancing software productivity. The emergence of large language models (LLMs) has significantly advanced code generation, though their efficiency is still impacted by certain inherent architectural constraints. Each token generation necessitates a complete inference pass, requiring persistent retention of contextual information in memory and escalating resource consumption. While existing research prioritizes inference-phase optimizations such as prompt compression and model quantization, the generation phase remains underexplored. To tackle these challenges, we propose a knowledge-infused framework named ShortCoder, which optimizes code generation efficiency while preserving semantic equivalence and readability. In particular, we introduce: (1) ten syntax-level simplification rules for Python, derived from AST-preserving transformations, achieving 18.1% token reduction without functional compromise; (2) a hybrid data synthesis pipeline integrating rule-based rewriting with LLM-guided refinement, producing ShorterCodeBench, a corpus of validated tuples of original code and simplified code with semantic consistency; (3) a fine-tuning strategy that injects conciseness awareness into the base LLMs. Extensive experimental results demonstrate that ShortCoder consistently outperforms state-of-the-art methods on HumanEval, achieving an improvement of 18.1%-37.8% in generation efficiency over previous methods while ensuring the performance of code generation.</summary>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-01-14T18:57:31Z</published>\n    <arxiv:primary_category term=\"cs.SE\"/>\n    <author>\n      <name>Sicong Liu</name>\n    </author>\n    <author>\n      <name>Yanxian Huang</name>\n    </author>\n    <author>\n      <name>Mingwei Liu</name>\n    </author>\n    <author>\n      <name>Jiachi Chen</name>\n    </author>\n    <author>\n      <name>Ensheng Shi</name>\n    </author>\n    <author>\n      <name>Yuchi Ma</name>\n    </author>\n    <author>\n      <name>Hongyu Zhang</name>\n    </author>\n    <author>\n      <name>Yin Zhang</name>\n    </author>\n    <author>\n      <name>Yanlin Wang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2504.11901v4</id>\n    <title>Causality-enhanced Decision-Making for Autonomous Mobile Robots in Dynamic Environments</title>\n    <updated>2026-01-14T18:52:06Z</updated>\n    <link href=\"https://arxiv.org/abs/2504.11901v4\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2504.11901v4\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The growing integration of robots in shared environments - such as warehouses, shopping centres, and hospitals - demands a deep understanding of the underlying dynamics and human behaviours, including how, when, and where individuals engage in various activities and interactions. This knowledge goes beyond simple correlation studies and requires a more comprehensive causal analysis. By leveraging causal inference to model cause-and-effect relationships, we can better anticipate critical environmental factors and enable autonomous robots to plan and execute tasks more effectively. To this end, we propose a novel causality-based decision-making framework that reasons over a learned causal model to assist the robot in deciding when and how to complete a given task. In the examined use case - i.e., a warehouse shared with people - we exploit the causal model to estimate battery usage and human obstructions as factors influencing the robot's task execution. This reasoning framework supports the robot in making informed decisions about task timing and strategy. To achieve this, we developed also PeopleFlow, a new Gazebo-based simulator designed to model context-sensitive human-robot spatial interactions in shared workspaces. PeopleFlow features realistic human and robot trajectories influenced by contextual factors such as time, environment layout, and robot state, and can simulate a large number of agents. While the simulator is general-purpose, in this paper we focus on a warehouse-like environment as a case study, where we conduct an extensive evaluation benchmarking our causal approach against a non-causal baseline. Our findings demonstrate the efficacy of the proposed solutions, highlighting how causal reasoning enables autonomous robots to operate more efficiently and safely in dynamic environments shared with humans.</summary>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-04-16T09:26:04Z</published>\n    <arxiv:comment>Causal Discovery and Inference - Robot Autonomy - Human-Robot Spatial Interaction - Decision-Making</arxiv:comment>\n    <arxiv:primary_category term=\"cs.RO\"/>\n    <author>\n      <name>Luca Castri</name>\n    </author>\n    <author>\n      <name>Gloria Beraldo</name>\n    </author>\n    <author>\n      <name>Nicola Bellotto</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2601.09694v1</id>\n    <title>LLMs can Compress LLMs: Adaptive Pruning by Agents</title>\n    <updated>2026-01-14T18:45:36Z</updated>\n    <link href=\"https://arxiv.org/abs/2601.09694v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2601.09694v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>As Large Language Models (LLMs) continue to scale, post-training pruning has emerged as a promising approach to reduce computational costs while preserving performance. Existing methods such as SparseGPT and Wanda achieve high sparsity through layer-wise weight reconstruction or activation-aware magnitude pruning, but rely on uniform or hand-crafted heuristics to determine per-layer sparsity ratios. Moreover, recent work has shown that pruned LLMs suffer from severe factual knowledge degradation, with structured pruning methods experiencing near-total collapse in factual question-answering capabilities. We introduce agent-guided pruning, where a foundation model acts as an adaptive pruning agent to intelligently select which layers to prune at each iteration while preserving critical knowledge pathways. Our method constructs layer-wise sensitivity profiles by combining Wanda-inspired weight-activation metrics with gradient importance scores, normalized as z-scores for model-agnostic comparison. These statistics are processed by an LLM agent equipped with self-reflection capabilities, enabling it to learn from previous pruning outcomes and iteratively refine its strategy. A checkpoint rollback mechanism maintains model quality by reverting when perplexity degradation exceeds a threshold. We evaluate our approach on Qwen3 models (4B and 8B parameters) at approximately 45% sparsity, demonstrating substantial improvements over structured pruning baselines: 56% relative improvement in MMLU accuracy, 19x better factual knowledge retention on FreebaseQA, and 69% lower perplexity degradation. Notably, our framework requires no retraining, operates in a model-agnostic manner, and exhibits effective self-correction with only 2-4 rollbacks across 21-40 iterations, demonstrating that foundation models can effectively guide the compression of other foundation models.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-01-14T18:45:36Z</published>\n    <arxiv:comment>17 Pages</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Sai Varun Kodathala</name>\n    </author>\n    <author>\n      <name>Rakesh Vunnam</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2601.09692v1</id>\n    <title>Routing with Generated Data: Annotation-Free LLM Skill Estimation and Expert Selection</title>\n    <updated>2026-01-14T18:43:32Z</updated>\n    <link href=\"https://arxiv.org/abs/2601.09692v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2601.09692v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large Language Model (LLM) routers dynamically select optimal models for given inputs. Existing approaches typically assume access to ground-truth labeled data, which is often unavailable in practice, especially when user request distributions are heterogeneous and unknown. We introduce Routing with Generated Data (RGD), a challenging setting in which routers are trained exclusively on generated queries and answers produced from high-level task descriptions by generator LLMs. We evaluate query-answer routers (using both queries and labels) and query-only routers across four diverse benchmarks and 12 models, finding that query-answer routers degrade faster than query-only routers as generator quality decreases. Our analysis reveals two crucial characteristics of effective generators: they must accurately respond to their own questions, and their questions must produce sufficient performance differentiation among the model pool. We then show how filtering for these characteristics can improve the quality of generated data. We further propose CASCAL, a novel query-only router that estimates model correctness through consensus voting and identifies model-specific skill niches via hierarchical clustering. CASCAL is substantially more robust to generator quality, outperforming the best query-answer router by 4.6% absolute accuracy when trained on weak generator data.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-01-14T18:43:32Z</published>\n    <arxiv:comment>Code: https://github.com/tianyiniu/RoutingGenData</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Tianyi Niu</name>\n    </author>\n    <author>\n      <name>Justin Chih-Yao Chen</name>\n    </author>\n    <author>\n      <name>Genta Indra Winata</name>\n    </author>\n    <author>\n      <name>Shi-Xiong Zhang</name>\n    </author>\n    <author>\n      <name>Supriyo Chakraborty</name>\n    </author>\n    <author>\n      <name>Sambit Sahu</name>\n    </author>\n    <author>\n      <name>Yue Zhang</name>\n    </author>\n    <author>\n      <name>Elias Stengel-Eskin</name>\n    </author>\n    <author>\n      <name>Mohit Bansal</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2601.09684v1</id>\n    <title>Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection</title>\n    <updated>2026-01-14T18:36:22Z</updated>\n    <link href=\"https://arxiv.org/abs/2601.09684v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2601.09684v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Multi-Task Learning (MTL) combined with Low-Rank Adaptation (LoRA) has emerged as a promising direction for parameter-efficient deployment of Large Language Models (LLMs). By sharing a single adapter across multiple tasks, one can significantly reduce storage overhead. However, this approach suffers from negative transfer, where conflicting gradient updates from distinct tasks degrade the performance of individual tasks compared to single-task fine-tuning. This problem is exacerbated in LoRA due to the low-rank constraint, which limits the optimization landscape's capacity to accommodate diverse task requirements. In this paper, we propose Ortho-LoRA, a gradient projection method specifically tailored for the bipartite structure of LoRA. Ortho-LoRA dynamically projects conflicting task gradients onto the orthogonal complement of each other within the intrinsic LoRA subspace. Extensive experiments on the GLUE benchmark demonstrate that Ortho-LoRA effectively mitigates task interference, outperforming standard joint training and recovering 95\\% of the performance gap between multi-task and single-task baselines with negligible computational overhead.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-01-14T18:36:22Z</published>\n    <arxiv:comment>preprint</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Ziyu Yang</name>\n    </author>\n    <author>\n      <name>Guibin Chen</name>\n    </author>\n    <author>\n      <name>Yuxin Yang</name>\n    </author>\n    <author>\n      <name>Aoxiong Zeng</name>\n    </author>\n    <author>\n      <name>Xiangquan Yang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2601.09680v1</id>\n    <title>Automating Supply Chain Disruption Monitoring via an Agentic AI Approach</title>\n    <updated>2026-01-14T18:28:31Z</updated>\n    <link href=\"https://arxiv.org/abs/2601.09680v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2601.09680v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Modern supply chains are increasingly exposed to disruptions from geopolitical events, demand shocks, trade restrictions, to natural disasters. While many of these disruptions originate deep in the supply network, most companies still lack visibility beyond Tier-1 suppliers, leaving upstream vulnerabilities undetected until the impact cascades downstream. To overcome this blind-spot and move from reactive recovery to proactive resilience, we introduce a minimally supervised agentic AI framework that autonomously monitors, analyses, and responds to disruptions across extended supply networks. The architecture comprises seven specialised agents powered by large language models and deterministic tools that jointly detect disruption signals from unstructured news, map them to multi-tier supplier networks, evaluate exposure based on network structure, and recommend mitigations such as alternative sourcing options. \\rev{We evaluate the framework across 30 synthesised scenarios covering three automotive manufacturers and five disruption classes. The system achieves high accuracy across core tasks, with F1 scores between 0.962 and 0.991, and performs full end-to-end analyses in a mean of 3.83 minutes at a cost of \\$0.0836 per disruption. Relative to industry benchmarks of multi-day, analyst-driven assessments, this represents a reduction of more than three orders of magnitude in response time. A real-world case study of the 2022 Russia-Ukraine conflict further demonstrates operational applicability. This work establishes a foundational step toward building resilient, proactive, and autonomous supply chains capable of managing disruptions across deep-tier networks.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-01-14T18:28:31Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Sara AlMahri</name>\n    </author>\n    <author>\n      <name>Liming Xu</name>\n    </author>\n    <author>\n      <name>Alexandra Brintrup</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.18856v3</id>\n    <title>Deep Hybrid Model for Region of Interest Detection in Omnidirectional Videos</title>\n    <updated>2026-01-14T18:25:35Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.18856v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.18856v3\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The main goal of the project is to design a new model that predicts regions of interest in 360$^{\\circ}$ videos. The region of interest (ROI) plays an important role in 360$^{\\circ}$ video streaming. For example, ROIs are used to predict view-ports, intelligently cut the videos for live streaming, etc so that less bandwidth is used. Detecting view-ports in advance helps reduce the movement of the head while streaming and watching a video via the head-mounted device. Whereas, intelligent cuts of the videos help improve the efficiency of streaming the video to users and enhance the quality of their viewing experience. This report illustrates the secondary task to identify ROIs, in which, we design, train, and test a hybrid saliency model. In this work, we refer to saliency regions to represent the regions of interest. The method includes the processes as follows: preprocessing the video to obtain frames, developing a hybrid saliency model for predicting the region of interest, and finally post-processing the output predictions of the hybrid saliency model to obtain the output region of interest for each frame. Then, we compare the performance of the proposed method with the subjective annotations of the 360RAT dataset.</summary>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-24T07:52:06Z</published>\n    <arxiv:comment>I need to withdraw this as it contains some confidential information related to FAPESP funding agency</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CV\"/>\n    <author>\n      <name>Sana Alamgeer</name>\n    </author>\n    <author>\n      <name>Mylene Farias</name>\n    </author>\n    <author>\n      <name>Marcelo Carvalho</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2601.05755v2</id>\n    <title>VIGIL: Defending LLM Agents Against Tool Stream Injection via Verify-Before-Commit</title>\n    <updated>2026-01-14T18:19:43Z</updated>\n    <link href=\"https://arxiv.org/abs/2601.05755v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2601.05755v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>LLM agents operating in open environments face escalating risks from indirect prompt injection, particularly within the tool stream where manipulated metadata and runtime feedback hijack execution flow. Existing defenses encounter a critical dilemma as advanced models prioritize injected rules due to strict alignment while static protection mechanisms sever the feedback loop required for adaptive reasoning. To reconcile this conflict, we propose \\textbf{VIGIL}, a framework that shifts the paradigm from restrictive isolation to a verify-before-commit protocol. By facilitating speculative hypothesis generation and enforcing safety through intent-grounded verification, \\textbf{VIGIL} preserves reasoning flexibility while ensuring robust control. We further introduce \\textbf{SIREN}, a benchmark comprising 959 tool stream injection cases designed to simulate pervasive threats characterized by dynamic dependencies. Extensive experiments demonstrate that \\textbf{VIGIL} outperforms state-of-the-art dynamic defenses by reducing the attack success rate by over 22\\% while more than doubling the utility under attack compared to static baselines, thereby achieving an optimal balance between security and utility.</summary>\n    <category term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-01-09T12:19:49Z</published>\n    <arxiv:primary_category term=\"cs.CR\"/>\n    <author>\n      <name>Junda Lin</name>\n    </author>\n    <author>\n      <name>Zhaomeng Zhou</name>\n    </author>\n    <author>\n      <name>Zhi Zheng</name>\n    </author>\n    <author>\n      <name>Shuochen Liu</name>\n    </author>\n    <author>\n      <name>Tong Xu</name>\n    </author>\n    <author>\n      <name>Yong Chen</name>\n    </author>\n    <author>\n      <name>Enhong Chen</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2507.07046v2</id>\n    <title>A Novel Hybrid Deep Learning Technique for Speech Emotion Detection using Feature Engineering</title>\n    <updated>2026-01-14T18:07:43Z</updated>\n    <link href=\"https://arxiv.org/abs/2507.07046v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2507.07046v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Nowadays, speech emotion recognition (SER) plays a vital role in the field of human-computer interaction (HCI) and the evolution of artificial intelligence (AI). Our proposed DCRF-BiLSTM model is used to recognize seven emotions: neutral, happy, sad, angry, fear, disgust, and surprise, which are trained on five datasets: RAVDESS (R), TESS (T), SAVEE (S), EmoDB (E), and Crema-D (C). The model achieves high accuracy on individual datasets, including 97.83% on RAVDESS, 97.02% on SAVEE, 95.10% for CREMA-D, and a perfect 100% on both TESS and EMO-DB. For the combined (R+T+S) datasets, it achieves 98.82% accuracy, outperforming previously reported results. To our knowledge, no existing study has evaluated a single SER model across all five benchmark datasets (i.e., R+T+S+C+E) simultaneously. In our work, we introduce this comprehensive combination and achieve a remarkable overall accuracy of 93.76%. These results confirm the robustness and generalizability of our DCRF-BiLSTM framework across diverse datasets.</summary>\n    <category term=\"cs.SD\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"eess.AS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-07-09T17:07:45Z</published>\n    <arxiv:comment>17 pages, 11 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.SD\"/>\n    <arxiv:journal_ref>HHAI-WS 2025 Workshops at the Fourth International Conference on Hybrid Human-Artificial Intelligence (HHAI), June, 2025, Pisa, Italy</arxiv:journal_ref>\n    <author>\n      <name>Shahana Yasmin Chowdhury</name>\n    </author>\n    <author>\n      <name>Bithi Banik</name>\n    </author>\n    <author>\n      <name>Md Tamjidul Hoque</name>\n    </author>\n    <author>\n      <name>Shreya Banerjee</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2601.09667v1</id>\n    <title>Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning</title>\n    <updated>2026-01-14T17:57:43Z</updated>\n    <link href=\"https://arxiv.org/abs/2601.09667v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2601.09667v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Multi-agent systems have evolved into practical LLM-driven collaborators for many applications, gaining robustness from diversity and cross-checking. However, multi-agent RL (MARL) training is resource-intensive and unstable: co-adapting teammates induce non-stationarity, and rewards are often sparse and high-variance. Therefore, we introduce \\textbf{Multi-Agent Test-Time Reinforcement Learning (MATTRL)}, a framework that injects structured textual experience into multi-agent deliberation at inference time. MATTRL forms a multi-expert team of specialists for multi-turn discussions, retrieves and integrates test-time experiences, and reaches consensus for final decision-making. We also study credit assignment for constructing a turn-level experience pool, then reinjecting it into the dialogue. Across challenging benchmarks in medicine, math, and education, MATTRL improves accuracy by an average of 3.67\\% over a multi-agent baseline, and by 8.67\\% over comparable single-agent baselines. Ablation studies examine different credit-assignment schemes and provide a detailed comparison of how they affect training outcomes. MATTRL offers a stable, effective and efficient path to distribution-shift-robust multi-agent reasoning without tuning.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-01-14T17:57:43Z</published>\n    <arxiv:comment>Work in Progress</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Zhiyuan Hu</name>\n    </author>\n    <author>\n      <name>Yunhai Hu</name>\n    </author>\n    <author>\n      <name>Juncheng Liu</name>\n    </author>\n    <author>\n      <name>Shuyue Stella Li</name>\n    </author>\n    <author>\n      <name>Yucheng Wang</name>\n    </author>\n    <author>\n      <name>Zhen Xu</name>\n    </author>\n    <author>\n      <name>See-Kiong Ng</name>\n    </author>\n    <author>\n      <name>Anh Tuan Luu</name>\n    </author>\n    <author>\n      <name>Xinxing Xu</name>\n    </author>\n    <author>\n      <name>Bryan Hooi</name>\n    </author>\n    <author>\n      <name>Cynthia Breazeal</name>\n    </author>\n    <author>\n      <name>Hae Won Park</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2601.07348v3</id>\n    <title>Controlled Self-Evolution for Algorithmic Code Optimization</title>\n    <updated>2026-01-14T17:53:44Z</updated>\n    <link href=\"https://arxiv.org/abs/2601.07348v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2601.07348v3\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Self-evolution methods enhance code generation through iterative \"generate-verify-refine\" cycles, yet existing approaches suffer from low exploration efficiency, failing to discover solutions with superior complexity within limited budgets. This inefficiency stems from initialization bias trapping evolution in poor solution regions, uncontrolled stochastic operations lacking feedback guidance, and insufficient experience utilization across tasks. To address these bottlenecks, we propose Controlled Self-Evolution (CSE), which consists of three key components. Diversified Planning Initialization generates structurally distinct algorithmic strategies for broad solution space coverage. Genetic Evolution replaces stochastic operations with feedback-guided mechanisms, enabling targeted mutation and compositional crossover. Hierarchical Evolution Memory captures both successful and failed experiences at inter-task and intra-task levels. Experiments on EffiBench-X demonstrate that CSE consistently outperforms all baselines across various LLM backbones. Furthermore, CSE achieves higher efficiency from early generations and maintains continuous improvement throughout evolution. Our code is publicly available at https://github.com/QuantaAlpha/EvoControl.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.NE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-01-12T09:23:13Z</published>\n    <arxiv:comment>27 pages</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Tu Hu</name>\n    </author>\n    <author>\n      <name>Ronghao Chen</name>\n    </author>\n    <author>\n      <name>Shuo Zhang</name>\n    </author>\n    <author>\n      <name>Jianghao Yin</name>\n    </author>\n    <author>\n      <name>Mou Xiao Feng</name>\n    </author>\n    <author>\n      <name>Jingping Liu</name>\n    </author>\n    <author>\n      <name>Shaolei Zhang</name>\n    </author>\n    <author>\n      <name>Wenqi Jiang</name>\n    </author>\n    <author>\n      <name>Yuqi Fang</name>\n    </author>\n    <author>\n      <name>Sen Hu</name>\n    </author>\n    <author>\n      <name>Yi Xu</name>\n    </author>\n    <author>\n      <name>Huacan Wang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.20294v2</id>\n    <title>Dynamics-Aligned Latent Imagination in Contextual World Models for Zero-Shot Generalization</title>\n    <updated>2026-01-14T17:50:26Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.20294v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.20294v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Real-world reinforcement learning demands adaptation to unseen environmental conditions without costly retraining. Contextual Markov Decision Processes (cMDP) model this challenge, but existing methods often require explicit context variables (e.g., friction, gravity), limiting their use when contexts are latent or hard to measure. We introduce Dynamics-Aligned Latent Imagination (DALI), a framework integrated within the Dreamer architecture that infers latent context representations from agent-environment interactions. By training a self-supervised encoder to predict forward dynamics, DALI generates actionable representations conditioning the world model and policy, bridging perception and control. We theoretically prove this encoder is essential for efficient context inference and robust generalization. DALI's latent space enables counterfactual consistency: Perturbing a gravity-encoding dimension alters imagined rollouts in physically plausible ways. On challenging cMDP benchmarks, DALI achieves significant gains over context-unaware baselines, often surpassing context-aware baselines in extrapolation tasks, enabling zero-shot generalization to unseen contextual variations.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-27T22:02:56Z</published>\n    <arxiv:comment>31 pages, 4 figures, accepted to NeurIPS 2025</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Frank RÃ¶der</name>\n    </author>\n    <author>\n      <name>Jan Benad</name>\n    </author>\n    <author>\n      <name>Manfred Eppe</name>\n    </author>\n    <author>\n      <name>Pradeep Kr. Banerjee</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2501.13165v2</id>\n    <title>QuFeX: Quantum feature extraction module for hybrid quantum-classical deep neural networks</title>\n    <updated>2026-01-14T17:48:11Z</updated>\n    <link href=\"https://arxiv.org/abs/2501.13165v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2501.13165v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>We introduce Quantum Feature Extraction (QuFeX), a novel quantum machine learning module. The proposed module enables feature extraction in a reduced-dimensional space, significantly decreasing the number of parallel evaluations required in typical quantum convolutional neural network architectures. Its design allows seamless integration into deep classical neural networks, making it particularly suitable for hybrid quantum-classical models. As an application of QuFeX, we propose Qu-Net -- a hybrid architecture which integrates QuFeX at the bottleneck of a U-Net architecture. The latter is widely used for image segmentation tasks such as medical imaging and autonomous driving. Our numerical analysis indicates that the Qu-Net can achieve superior segmentation performance compared to a U-Net baseline. These results highlight the potential of QuFeX to enhance deep neural networks by leveraging hybrid computational paradigms, providing a path towards a robust framework for real-world applications requiring precise feature extraction.</summary>\n    <category term=\"quant-ph\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-01-22T19:00:09Z</published>\n    <arxiv:comment>V2: 17 pages, 15 figures, 2 Tables; published version</arxiv:comment>\n    <arxiv:primary_category term=\"quant-ph\"/>\n    <arxiv:journal_ref>Quantum Sci. Technol. 11 015017 (2026)</arxiv:journal_ref>\n    <author>\n      <name>Naman Jain</name>\n    </author>\n    <author>\n      <name>Amir Kalev</name>\n    </author>\n    <arxiv:doi>10.1088/2058-9565/ae24a8</arxiv:doi>\n    <link rel=\"related\" href=\"https://doi.org/10.1088/2058-9565/ae24a8\" title=\"doi\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2411.04946v3</id>\n    <title>SPGD: Steepest Perturbed Gradient Descent Optimization</title>\n    <updated>2026-01-14T17:20:45Z</updated>\n    <link href=\"https://arxiv.org/abs/2411.04946v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2411.04946v3\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Optimization algorithms are pivotal in advancing various scientific and industrial fields but often encounter obstacles such as trapping in local minima, saddle points, and plateaus (flat regions), which makes the convergence to reasonable or near-optimal solutions particularly challenging. This paper presents the Steepest Perturbed Gradient Descent (SPGD), a novel algorithm that innovatively combines the principles of the gradient descent method with periodic uniform perturbation sampling to effectively circumvent these impediments and lead to better solutions whenever possible. SPGD is distinctively designed to generate a set of candidate solutions and select the one exhibiting the steepest loss difference relative to the current solution. It enhances the traditional gradient descent approach by integrating a strategic exploration mechanism that significantly increases the likelihood of escaping sub-optimal local minima and navigating complex optimization landscapes effectively. Our approach not only retains the directed efficiency of gradient descent but also leverages the exploratory benefits of stochastic perturbations, thus enabling a more comprehensive search for global optima across diverse problem spaces. We demonstrate the efficacy of SPGD in solving the 3D component packing problem, an NP-hard challenge. Preliminary results show a substantial improvement over four established methods, particularly on response surfaces with complex topographies and in multidimensional non-convex continuous optimization problems. Comparative analyses with established 2D benchmark functions highlight SPGD's superior performance, showcasing its ability to navigate complex optimization landscapes. These results emphasize SPGD's potential as a versatile tool for a wide range of optimization problems.</summary>\n    <category term=\"math.OC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math-ph\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2024-11-07T18:23:30Z</published>\n    <arxiv:comment>28 pages, 26 figures, submitted to Journal of Mechanical Design</arxiv:comment>\n    <arxiv:primary_category term=\"math.OC\"/>\n    <arxiv:journal_ref>ASME. J. Mech. Des. (January 14, 2026)</arxiv:journal_ref>\n    <author>\n      <name>Amir M. Vahedi</name>\n    </author>\n    <author>\n      <name>Horea T. Ilies</name>\n    </author>\n    <arxiv:doi>10.1115/1.4070858</arxiv:doi>\n    <link rel=\"related\" href=\"https://doi.org/10.1115/1.4070858\" title=\"doi\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.09676v2</id>\n    <title>Coupled Data and Measurement Space Dynamics for Enhanced Diffusion Posterior Sampling</title>\n    <updated>2026-01-14T17:17:22Z</updated>\n    <link href=\"https://arxiv.org/abs/2510.09676v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2510.09676v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Inverse problems, where the goal is to recover an unknown signal from noisy or incomplete measurements, are central to applications in medical imaging, remote sensing, and computational biology. Diffusion models have recently emerged as powerful priors for solving such problems. However, existing methods either rely on projection-based techniques that enforce measurement consistency through heuristic updates, or they approximate the likelihood $p(\\boldsymbol{y} \\mid \\boldsymbol{x})$, often resulting in artifacts and instability under complex or high-noise conditions. To address these limitations, we propose a novel framework called \\emph{coupled data and measurement space diffusion posterior sampling} (C-DPS), which eliminates the need for constraint tuning or likelihood approximation. C-DPS introduces a forward stochastic process in the measurement space $\\{\\boldsymbol{y}_t\\}$, evolving in parallel with the data-space diffusion $\\{\\boldsymbol{x}_t\\}$, which enables the derivation of a closed-form posterior $p(\\boldsymbol{x}_{t-1} \\mid \\boldsymbol{x}_t, \\boldsymbol{y}_{t-1})$. This coupling allows for accurate and recursive sampling based on a well-defined posterior distribution. Empirical results demonstrate that C-DPS consistently outperforms existing baselines, both qualitatively and quantitatively, across multiple inverse problem benchmarks.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-10-08T18:59:16Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Shayan Mohajer Hamidi</name>\n    </author>\n    <author>\n      <name>En-Hui Yang</name>\n    </author>\n    <author>\n      <name>Ben Liang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.23003v2</id>\n    <title>Physically Plausible Multi-System Trajectory Generation and Symmetry Discovery</title>\n    <updated>2026-01-14T17:15:25Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.23003v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.23003v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>From metronomes to celestial bodies, mechanics underpins how the world evolves in time and space. With consideration of this, a number of recent neural network models leverage inductive biases from classical mechanics to encourage model interpretability and ensure forecasted states are physical. However, in general, these models are designed to capture the dynamics of a single system with fixed physical parameters, from state-space measurements of a known configuration space. In this paper we introduce Symplectic Phase Space GAN (SPS-GAN) which can capture the dynamics of multiple systems, and generalize to unseen physical parameters from. Moreover, SPS-GAN does not require prior knowledge of the system configuration space. In fact, SPS-GAN can discover the configuration space structure of the system from arbitrary measurement types (e.g., state-space measurements, video frames). To achieve physically plausible generation, we introduce a novel architecture which embeds a Hamiltonian neural network recurrent module in a conditional GAN backbone. To discover the structure of the configuration space, we optimize the conditional time-series GAN objective with an additional physically motivated term to encourages a sparse representation of the configuration space. We demonstrate the utility of SPS-GAN for trajectory prediction, video generation and symmetry discovery. Our approach captures multiple systems and achieves performance on par with supervised models designed for single systems.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"eess.SY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-26T23:46:55Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Jiayin Liu</name>\n    </author>\n    <author>\n      <name>Yulong Yang</name>\n    </author>\n    <author>\n      <name>Vineet Bansal</name>\n    </author>\n    <author>\n      <name>Christine Allen-Blanchette</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2601.09636v1</id>\n    <title>PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent with Long-Term User-Centric Records</title>\n    <updated>2026-01-14T17:12:48Z</updated>\n    <link href=\"https://arxiv.org/abs/2601.09636v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2601.09636v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>While GUI agents have shown strong performance under explicit and completion instructions, real-world deployment requires aligning with users' more complex implicit intents. In this work, we highlight Hierarchical Implicit Intent Alignment for Personalized GUI Agent (PersonalAlign), a new agent task that requires agents to leverage long-term user records as persistent context to resolve omitted preferences in vague instructions and anticipate latent routines by user state for proactive assistance. To facilitate this study, we introduce AndroidIntent, a benchmark designed to evaluate agents' ability in resolving vague instructions and providing proactive suggestions through reasoning over long-term user records. We annotated 775 user-specific preferences and 215 routines from 20k long-term records across different users for evaluation. Furthermore, we introduce Hierarchical Intent Memory Agent (HIM-Agent), which maintains a continuously updating personal memory and hierarchically organizes user preferences and routines for personalization. Finally, we evaluate a range of GUI agents on AndroidIntent, including GPT-5, Qwen3-VL, and UI-TARS, further results show that HIM-Agent significantly improves both execution and proactive performance by 15.7% and 7.3%.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-01-14T17:12:48Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Yibo Lyu</name>\n    </author>\n    <author>\n      <name>Gongwei Chen</name>\n    </author>\n    <author>\n      <name>Rui Shao</name>\n    </author>\n    <author>\n      <name>Weili Guan</name>\n    </author>\n    <author>\n      <name>Liqiang Nie</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2601.09635v1</id>\n    <title>LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach</title>\n    <updated>2026-01-14T17:09:57Z</updated>\n    <link href=\"https://arxiv.org/abs/2601.09635v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2601.09635v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large-scale optimization is a key backbone of modern business decision-making. However, building these models is often labor-intensive and time-consuming. We address this by proposing LEAN-LLM-OPT, a LightwEight AgeNtic workflow construction framework for LLM-assisted large-scale OPTimization auto-formulation. LEAN-LLM-OPT takes as input a problem description together with associated datasets and orchestrates a team of LLM agents to produce an optimization formulation. Specifically, upon receiving a query, two upstream LLM agents dynamically construct a workflow that specifies, step-by-step, how optimization models for similar problems can be formulated. A downstream LLM agent then follows this workflow to generate the final output. Leveraging LLMs' text-processing capabilities and common modeling practices, the workflow decomposes the modeling task into a sequence of structured sub-tasks and offloads mechanical data-handling operations to auxiliary tools. This design alleviates the downstream agent's burden related to planning and data handling, allowing it to focus on the most challenging components that cannot be readily standardized. Extensive simulations show that LEAN-LLM-OPT, instantiated with GPT-4.1 and the open source gpt-oss-20B, achieves strong performance on large-scale optimization modeling tasks and is competitive with state-of-the-art approaches. In addition, in a Singapore Airlines choice-based revenue management use case, LEAN-LLM-OPT demonstrates practical value by achieving leading performance across a range of scenarios. Along the way, we introduce Large-Scale-OR and Air-NRM, the first comprehensive benchmarks for large-scale optimization auto-formulation. The code and data of this work is available at https://github.com/CoraLiang01/lean-llm-opt.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2026-01-14T17:09:57Z</published>\n    <arxiv:comment>Updated version of https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5329027</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Kuo Liang</name>\n    </author>\n    <author>\n      <name>Yuhang Lu</name>\n    </author>\n    <author>\n      <name>Jianming Mao</name>\n    </author>\n    <author>\n      <name>Shuyi Sun</name>\n    </author>\n    <author>\n      <name>Chunwei Yang</name>\n    </author>\n    <author>\n      <name>Congcong Zeng</name>\n    </author>\n    <author>\n      <name>Xiao Jin</name>\n    </author>\n    <author>\n      <name>Hanzhang Qin</name>\n    </author>\n    <author>\n      <name>Ruihao Zhu</name>\n    </author>\n    <author>\n      <name>Chung-Piaw Teo</name>\n    </author>\n  </entry>\n</feed>\n",
  "httpStatus": 200
}